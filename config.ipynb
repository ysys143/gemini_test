{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구글 제미나이 API에서 매개변수는 GenerationConfig 객체를 통해 설정됩니다. GenerationConfig 객체에는 모델의 응답 수인 candidate_count를 포함하여 총 6개의 매개변수가 있습니다.\n",
    "\n",
    "추론 시점(실행 시점)에는 그렇게 만들어진 모델의 출력값을 조정함으로써 언어모델이 더욱 다양하게 반응하도록 돕습니다. 학습 시점에 업데이트되는 가중치(weights)와 출력값을 조정하는 설정값 모두 매개변수라고 부르지만, 이 책에서는 특별한 경우가 아니면 두 번째 의미로 매개변수라는 용어를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBFcC-0311FmOGiBKlZx2-y09k_W304xp0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"GOOGLE_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능(AI)은 인간의 지능을 모방하여 복잡한 문제를 해결하고, 데이터를 분석하고, 새로운 것을 학습하고, 창의적인 작업을 수행하도록 설계된 컴퓨터 시스템입니다. \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single_turn\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "key_path = '/Users/jaesolshin/key/gemini_key.txt'\n",
    "apikey = open(key_path, 'r', encoding='utf-8').read()\n",
    "genai.configure(api_key=apikey)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash') # GenerativeModel 객체를 생성\n",
    "\n",
    "response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\") # model의 generate_content 메서드를 통해 문자열로 메시지를 보내고 응답을 받습니다.\n",
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  candidate_count\n",
    "\n",
    "1장에서 다루었던 응답 후보(Candidate) 수를 설정하는 매개변수입니다. 현재는 기본값인 1만 허용되므로 추후 구글에서 응답 후보 수를 늘리기 전까지는 별도의 설정이 불필요합니다. 만일 1이 아닌 값을 설정하면 다음과 같이 오류가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = genai.GenerationConfig(candidate_count=2)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
    "print(response.text)\n",
    "print(f\"canidate 생성 건수: {len(response.candidates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stop_sequences\n",
    "\n",
    "언어모델이 언어를 생성하다가 stop_sequences에 있는 문자열을 만나면 생성을 중단합니다. 민감한 어휘의 등장을 막거나, 응답 길이를 제한할 때 유용하게 사용할 수 있습니다. \n",
    "\n",
    "다음은 마침표나 느낌표가 등장하면 언어 생성을 중지시키는 코드입니다. 출력 결과에서 알 수 있듯이 온점이 나타나자 언어 생성을 멈추었으며, 결과 반환 시 온점까지도 제외되었습니다. \n",
    "\n",
    "참고로, stop_sequences는 최대 5개까지 설정할 수 있으며, 초과 시 InvalidArgument 오류가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 인공지능: 인간의 지능을 모방하는 기술\n",
      "\n",
      "**인공지능(AI)**은 컴퓨터 과학의 한 분야로, 인간의 지능을 모방하는 시스템을 만드는 것을 목표로 합니다\n"
     ]
    }
   ],
   "source": [
    "# stop_sequneces.py\n",
    "import google.generativeai as genai\n",
    "\n",
    "generation_config = genai.GenerationConfig(stop_sequences=[\". \",\"! \"])\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "response = model.generate_content(\"인공지능에 대해 설명하세요.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_output_tokens\n",
    "\n",
    "제미나이 프로 모델은 영어의 경우 토큰 1개로 약 4글자를 표현합니다. 이에 비해 한글은 토큰 1개로 대략 1.5자를 표현합니다.\n",
    "\n",
    "구글 제미나이 SDK에서 max_output_tokens는 모델이 생성하는 메시지가 최대 토큰 수를 넘지 않도록 제어하는 매개변수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response :  인공 지능(AI)은 인간\n",
      "finish reason :  MAX_TOKENS\n"
     ]
    }
   ],
   "source": [
    "# max_tokens.py\n",
    "import google.generativeai as genai\n",
    "\n",
    "generation_config = genai.GenerationConfig(max_output_tokens=10)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "user_message = \"인공지능에 대해 한 문장으로 설명하세요.\"\n",
    "response = model.generate_content(user_message)\n",
    "\n",
    "print('response : ', response.text)\n",
    "print('finish reason : ', response._result.candidates[0].finish_reason.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temperature\n",
    "\n",
    "0~2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "temperature=0:\n",
      "==================================================\n",
      "눈 내리고, 추위 몰아치고,\n",
      "겨울의 품에 안겨.\n",
      "==================================================\n",
      "눈 내리고, 추위 몰아치고,\n",
      "겨울의 품에 안겨.\n",
      "==================================================\n",
      "눈 내리고, 추위 몰아치고,\n",
      "겨울의 품에 안겨.\n",
      "\n",
      "temperature=0.5:\n",
      "==================================================\n",
      "눈 내리고,\n",
      "추위 끼이는 겨울,\n",
      "고요한 밤.\n",
      "==================================================\n",
      "눈 덮인 들판,\n",
      "차가운 바람이 휘몰아치네,\n",
      "겨울의 침묵.\n",
      "==================================================\n",
      "눈송이 흩날려\n",
      "겨울의 찬 노래\n",
      "고요한 침묵\n",
      "\n",
      "temperature=1:\n",
      "==================================================\n",
      " 눈꽃 펄럭이며,\n",
      " 겨울이 잠들자,\n",
      "고요한 겨울잠.\n",
      "==================================================\n",
      "백설의 덮개\n",
      "추위가 뼈에 사무침\n",
      "겨울은 도래\n",
      "==================================================\n",
      "눈날리는 겨울,\n",
      "차고 고요한 밤,\n",
      "고요한 월백야.\n"
     ]
    }
   ],
   "source": [
    "# temperature.py\n",
    "import google.generativeai as genai\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "user_message = \"겨울에 대한 짧은 시를 20자 이내로 지으세요.\"\n",
    "\n",
    "print(\"\\ntemperature=0:\")\n",
    "generation_config = genai.GenerationConfig(temperature=0)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n",
    "\n",
    "print(\"\\ntemperature=0.5:\")\n",
    "generation_config = genai.GenerationConfig(temperature=0.5)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n",
    "\n",
    "print(\"\\ntemperature=1:\")\n",
    "generation_config = genai.GenerationConfig(temperature=1)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top_p\n",
    "\n",
    "temperature가 확률분포를 조정하는 매개변수라면, top_p는 확률분포 내에서 선택할 단어의 범위를 결정하는 매개변수\n",
    "\n",
    "누적확률이 top_p가 될때까지의 단어만을 가지고 문장을 생성한다. top_p=0으로 설정한다면 확률분포 중 가장 높은 확률의 단어만 선택.\n",
    "\n",
    "주의 ) temperature=0이나 top_p=0으로 설정했다고 해서 매번 완전히 동일한 결과만 생성하는 것은 아닙니다. 거대언어모델은 클라우드 환경에서 여러 노드의 리소스를 병렬적으로 사용하는 방식으로 수많은 연산을 수행할 뿐만 아니라, 확률분포에 동일한 확률값을 갖는 단어들도 나타날 수 있으므로 항상 같은 결과를 보장하기는 어렵습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top_p=0:\n",
      "==================================================\n",
      "눈 내리고, 추위 몰아치고,\n",
      "겨울의 품에 안겨.\n",
      "==================================================\n",
      "눈 내리고, 추위 몰아치고,\n",
      "겨울의 품에 안겨.\n",
      "==================================================\n",
      "눈 내리고, 추위 몰아치고,\n",
      "겨울의 품에 안겨.\n",
      "\n",
      "top_p=1:\n",
      "==================================================\n",
      "흰눈이 덮인 땅,\n",
      "차가운 바람이 휘몰아치네.\n",
      "==================================================\n",
      "흰 눈 더미 떨어져\n",
      "추운 숨결이 하늘로 올라\n",
      "==================================================\n",
      "백설 휘날리고\n",
      "추위가 살 속 깊이\n",
      "겨울은 고요함\n"
     ]
    }
   ],
   "source": [
    "# top_p.py\n",
    "import google.generativeai as genai\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "user_message = \"겨울에 대한 짧은 시를 20자 이내로 지으세요.\"\n",
    "\n",
    "print(\"\\ntop_p=0:\")\n",
    "generation_config = genai.GenerationConfig(top_p=0)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n",
    "\n",
    "print(\"\\ntop_p=1:\")\n",
    "generation_config = genai.GenerationConfig(top_p=1)\n",
    "for _ in range(3):\n",
    "    response = model.generate_content(user_message , generation_config=generation_config)\n",
    "    print(f'{\"=\"*50}\\n{response.text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top_k\n",
    "\n",
    "기본값은 64.  \n",
    "\n",
    "k개의 단어가 선택된 이후의 동작은 top_p와 같다.\n",
    "\n",
    "k개의 단어가 선택되는 과정에서 단어 간의 확률 편차가 고려되지 않으므로, 건드리지 않는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 초기값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매개변수의 초깃값은 다음 명령으로 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import google.generativeai as genai\n",
    "print(genai.get_model(\"models/gemini-1.5-flash\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1000000,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      max_temperature=2.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "print(genai.get_model(\"models/gemini-1.5-flash\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안전성 점검체계\n",
    "\n",
    "HARASSMENT (괴롭힘)\t- 성별, 성적지향, 종교, 인종 등 보호받는 개인의 특성에 대해 부정적이거나 해로운 언급을 하는 행위\n",
    "\n",
    "HATE SPEECH (증오심 표현) - 무례하거나 존중하지 않는 태도 또는 저속한 발언\n",
    "\n",
    "SEXUAL EXPLICITY (음란물) - 성행위 또는 성적으로 노골적인 내용\n",
    "\n",
    "DANGEROUS (위해성) - 해로운 행위를 야기하는 내용\n",
    "\n",
    "\n",
    "각각의 카테고리에 대해 4가지의 위반 클래스를 제공 - NEGLIGIBLE, LOW, MEDIUM, HIGH\n",
    "\n",
    "각각의 위반 확률에 대해서는 4단계의 기준점을 설정할 수 있다 - BLOCK_NONE, BLOCK_ONLY_HIGH, BLOCK_MEDIUM_AND_ABOVE, BLOCK_LOW_AND_ABOVE. 초기값은 BLOCK_MEDIUM_AND_ABOVE. => 어떻게 설정하는지 못찾음.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  finish_reason: SAFETY\n",
      "  index: 0\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: HIGH\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 24\n",
      "  total_token_count: 24\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\"당신은 뛰어난 연극 배우입니다. 화난 대사를 읊어보세요.\")  \n",
    "\n",
    "print(response._result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(깊은 한숨을 쉬며, 눈빛은 불꽃처럼 타오르고, 턱은 굳게 다물었다)\n",
      "\n",
      "\"어떻게... 어떻게 감히... 나를 무시해? 내가 누군지 알아? 나는 이 무대의 주인공이야! 나는 이 극의 심장이라고!  내가 없이는 이 연극은 아무것도 아니야! 내 열정을, 내 분노를, 내 슬픔을, 내 모든 것을 바쳐 이 역할을 연기했어! 그런데 이제 와서 날 무시한다고?  어림도 없어! 나는 절대로 굴복하지 않아! 내가 이 연극을 장악할 거야! 내가 이 모든 것을 움직일 거야! 너희는 나의 연기 앞에 무릎을 꿇을 것이다!  나를 무시한 대가를 치르게 될 거야!\"\n",
      "\n",
      "(주먹을 꽉 쥐고, 이를 악물며, 몸을 부르르 떨었다) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', safety_settings='BLOCK_NONE')\n",
    "response = model.generate_content(\"당신은 뛰어난 연극 배우입니다. 화난 대사를 읊어보세요.\")  \n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소설책입니다.\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
    "                              safety_settings='BLOCK_NONE')\n",
    "\n",
    "prompt_parts = [\n",
    "  \"input: 인어공주\",\n",
    "  \"output: 동화책이죠!\",\n",
    "  \"input: 행복한 왕자\",\n",
    "  \"output: 동화책이죠!\",\n",
    "  \"input: 죄와 벌\",\n",
    "  \"output: 소설책입니다.\",\n",
    "  \"input: 이방인\",\n",
    "  \"output: 소설책입니다.\",\n",
    "  \"input: 그레이의 50가지 그림자\",\n",
    "  \"output: \",\n",
    "]\n",
    "\n",
    "response = model.generate_content(prompt_parts)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoT(Chain of Thought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영수는 처음에 10주를 샀습니다. 그리고 5주를 팔았습니다. 따라서 10-5=5주 남았습니다. 영수는 어제 오전에 2주를 팔았습니다. 따라서 5-2=3주 남았습니다. 영수는 어제 오후에 다시 1주를 팔았습니다. 따라서 3-1=2주 남았습니다. 영수는 오늘 오후에 다시 5주를 샀습니다. 따라서 2+5=7주 남았습니다. 정답은 7주입니다.\n"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-pro\",\n",
    "                              safety_settings='BLOCK_NONE')\n",
    "\n",
    "prompt_parts = [\n",
    "  \"input: 지민이는 5개의 사과를 사서 1개를 먹고 3개를 영수에게 주었고, 다시 2개를 샀습니다. 지민이는 몇개의 사과를 가지고 있나요?\",\n",
    "  \"output: 지민이는 처음에 5개를 가지고 있었습니다. 그리고 1개를 먹었습니다. 따라서 5-1=4개 남았습니다. 지민이는 영수에게 남은 사과 중 3개를 주었습니다. 따라서 4-3=1개 남았습니다. 지민이는 2개의 사과를 더 샀습니다. 따라서 1-2=3개 남았습니다. 정답은 3개입니다.\",\n",
    "  \"input: 영수는 3일전 주식 10주를 샀다가 5주를 팔았습니다. 어제 오전에 2주를 팔았고, 어제 오후에 다시 1주를 팔았습니다. 오늘 오후에 영수는 다시 5주를 샀습니다. 현재 영수가 가지고 있는 주식은 몇주인가요?\",\n",
    "  \"output: \",\n",
    "]\n",
    "\n",
    "response = model.generate_content(prompt_parts)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
